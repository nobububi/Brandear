{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データが大きすぎるために起きる問題点と解決策\n",
    "\n",
    "- 提出元データ\n",
    "    - 現状候補となるレコードが数十億(6000 * 600000)あり、特徴量エンジニアリングに時間がかかってしまう\n",
    "        - 学習用バリデーションデータでpdcaを早く回したいので、せめて数千万程度にしたい\n",
    "    - 正解となるレコードがより多く含まれている状態にしたい\n",
    "\n",
    "- 学習用データ\n",
    "    - 提出時に含まれるデータと同じような分布になって欲しいため、同じような前処理で作成したい\n",
    "        - 同じように作成した場合は、特徴量エンジニアリングに時間がかかってしまう\n",
    "    - データが多過ぎると、lightgbmのアンサンブルにしても時間がかかる\n",
    "    - 正解データは多く持っていた方が良いと思われる\n",
    "    - とりあえず正解データに適当にサンプリングしたオークションを付け加えたらどうにかなりそう?\n",
    "    \n",
    "- 学習用バリデーションデータ\n",
    "    - 提出用データ作成時と同様の処理をすることを考えると、特徴量エンジニアリングに時間がかかってしまう\n",
    "        - 学習用バリデーションデータでpdcaを早く回したいので、せめて数千万程度にしたい    \n",
    "        \n",
    "tobe\n",
    "- 提出元データ\n",
    "    - 数千万程度で、正解となるレコードがより多く含まれている状態にしたい\n",
    "- 学習用バリデーションデータ\n",
    "    - 提出元データと同じ\n",
    "- 学習用データ\n",
    "    - 数千万程度、提出用データと同じような分布を持っており、提出時に無いようなデータに過学習しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname\n",
    "import os\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import brandear_est as be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.path.join(os.getcwd(), \"../../data/input/\")\n",
    "IMD_DIR = os.path.join(os.getcwd(), \"../../data/intermediate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_to_period = {\n",
    "    \"train\": {\"oldest\": datetime.datetime(2019, 9, 3, 0, 0, 0),\n",
    "              \"newest\": datetime.datetime(2019, 9, 10, 0, 0, 0)},\n",
    "    \"valid_for_train\": {\"oldest\": datetime.datetime(2019, 9, 10, 0, 0, 0),\n",
    "              \"newest\": datetime.datetime(2019, 9, 17, 0, 0, 0),},\n",
    "    \"valid_for_sub\": {\"oldest\": datetime.datetime(2019, 9, 17, 0, 0, 0),\n",
    "              \"newest\": datetime.datetime(2019, 9, 24, 0, 0, 0),}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 137.17 Mb (66.3% reduction)\n",
      "Mem. usage decreased to 67.53 Mb (46.9% reduction)\n",
      "Mem. usage decreased to 13.44 Mb (58.9% reduction)\n",
      "Mem. usage decreased to  9.45 Mb (54.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "auction = be.read_csv(INPUT_DIR + \"auction.csv\")\n",
    "watch = be.read_csv(INPUT_DIR + \"watchlist.csv\")\n",
    "bid = be.read_csv(INPUT_DIR + \"shudounyuusatsu.csv\")\n",
    "bid_success = be.read_csv(INPUT_DIR + \"rakusatsu.csv\")\n",
    "\n",
    "watch = be.to_datetime(watch)\n",
    "bid = be.to_datetime(bid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62369\n",
      "66680\n",
      "68682\n",
      "38113\n",
      "41251\n",
      "26397\n"
     ]
    }
   ],
   "source": [
    "# アクションを起こされているオークションは、前週においてもアクションを起こされているものがかなり多いことがわかる\n",
    "train_ans = be.extract_target_actions(watch, bid, dset_to_period[\"train\"])\n",
    "vt_ans = be.extract_target_actions(watch, bid, dset_to_period[\"valid_for_train\"])\n",
    "vs_ans = be.extract_target_actions(watch, bid, dset_to_period[\"valid_for_sub\"])\n",
    "\n",
    "print(train_ans[[\"AuctionID\"]].drop_duplicates().shape[0])\n",
    "print(vt_ans[[\"AuctionID\"]].drop_duplicates().shape[0])\n",
    "print(vs_ans[[\"AuctionID\"]].drop_duplicates().shape[0])\n",
    "\n",
    "print(train_ans[[\"AuctionID\"]].merge(vt_ans[[\"AuctionID\"]]).shape[0])\n",
    "print(vt_ans[[\"AuctionID\"]].merge(vs_ans[[\"AuctionID\"]]).shape[0])\n",
    "print(train_ans[[\"AuctionID\"]].merge(vs_ans[[\"AuctionID\"]]).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 商品以外のもので履歴を探した時にどのくらいの正解率含有割合を作れるか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(watch, bid, auction, dset_type, dset_to_period, target_users=None, col=\"ShouhinID\"):\n",
    "    oldest_dtime, newest_dtime = (\n",
    "        dset_to_period[dset_type][\"oldest\"],\n",
    "        dset_to_period[dset_type][\"newest\"]\n",
    "    )\n",
    "\n",
    "    # データセット作成の対象となるユーザー一覧\n",
    "    if dset_type != \"submission\":\n",
    "        watch_actioned = (\n",
    "            watch[(watch[\"ActionDate\"] >= oldest_dtime) & (watch[\"ActionDate\"] < newest_dtime)]\n",
    "        )\n",
    "        bid_actioned = (\n",
    "            bid[(bid[\"ActionDate\"] >= oldest_dtime) & (bid[\"ActionDate\"] < newest_dtime)]\n",
    "        )\n",
    "        target_users = (\n",
    "            pd.concat([watch_actioned, bid_actioned], sort=False)[[\"KaiinID\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        \n",
    "    watch_targeted = watch.merge(target_users, on=\"KaiinID\")\n",
    "    bid_targeted = bid.merge(target_users, on=\"KaiinID\")\n",
    "\n",
    "    # リークを防ぐため、特徴量、choiced_auc作成用のデータから正解データ抽出期間時のデータを削除する\n",
    "    watch_train = watch_targeted[watch_targeted[\"ActionDate\"] < oldest_dtime]\n",
    "    bid_train = bid_targeted[bid_targeted[\"ActionDate\"] < oldest_dtime]\n",
    "\n",
    "    # 予測対象とするオークションをルール,0次ベースのロジックで限定する\n",
    "    dataset = merge_choiced_aucs(target_users, watch_train, bid_train, auction, col)\n",
    "\n",
    "    # 正解データ付与\n",
    "    if dset_type != \"submission\":\n",
    "        watch_actioned[\"watch_actioned\"] = 1\n",
    "        bid_actioned[\"bid_actioned\"] = 1\n",
    "        dataset = (\n",
    "            dataset\n",
    "                .merge(watch_actioned[[\"KaiinID\", \"AuctionID\", \"watch_actioned\"]], on=[\"KaiinID\", \"AuctionID\"],\n",
    "                       how=\"left\")\n",
    "                .merge(bid_actioned[[\"KaiinID\", \"AuctionID\", \"bid_actioned\"]], on=[\"KaiinID\", \"AuctionID\"], how=\"left\")\n",
    "                .fillna(0)\n",
    "        )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_choiced_aucs(target_users, watch, bid, auction, col=\"ShouhinID\"):\n",
    "    # choiced_auc付与部分\n",
    "    # あるユーザーが現在までにアクションをした商品と同じ商品IDのオークションを抽出\n",
    "    # これが関数内で作成する学習データの大元\n",
    "    target_aucs = (\n",
    "        pd.concat([watch[[\"KaiinID\", col]], bid[[\"KaiinID\", col]]])\n",
    "            .drop_duplicates()\n",
    "            .merge(auction[[\"AuctionID\", col]], on=col)[[\"KaiinID\", \"AuctionID\"]]\n",
    "            .drop_duplicates()\n",
    "    )\n",
    "\n",
    "    auc_cols = (\n",
    "        ['AuctionID', 'ShouhinShubetsuID', 'ShouhinID', 'SaishuppinKaisuu',\n",
    "         'ConditionID', 'BrandID', 'GenreID', 'GenreGroupID', 'LineID',\n",
    "         'DanjobetsuID']\n",
    "    )\n",
    "\n",
    "    # 今回の対象ユーザーに絞る\n",
    "    target_data = (\n",
    "        target_users\n",
    "            .merge(target_aucs, on=\"KaiinID\")\n",
    "            .merge(auction[auc_cols], on=\"AuctionID\")\n",
    "    )\n",
    "\n",
    "    return target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShouhinID\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nobuyuki.ishida/.pyenv/versions/3.7.5/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/nobuyuki.ishida/.pyenv/versions/3.7.5/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watch_actioned    3302.0\n",
      "bid_actioned      3718.0\n",
      "dtype: float64\n",
      "3284142\n",
      "BrandID\n"
     ]
    }
   ],
   "source": [
    "dset_type = \"train\"\n",
    "col_dset = {}\n",
    "for col in [\"ShouhinID\", \"BrandID\", \"GenreID\", \"GenreGroupID\", \"LineID\", \"ColorID\", \"DanjobetsuID\"]:\n",
    "    print(col)\n",
    "    col_dset[col] = build_dataset(watch, bid, auction, dset_type, dset_to_period, target_users=None, col=col)\n",
    "    print(col_dset[col][[\"watch_actioned\", \"bid_actioned\"]].sum())\n",
    "    print(col_dset[col].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アクションを起こしたユーザーがどのくらい同じ商品にアクションするかを調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_actions(watch, bid, dset_to_period, dset_type):\n",
    "\n",
    "    oldest_dtime, newest_dtime = (\n",
    "        dset_to_period[dset_type][\"oldest\"],\n",
    "        dset_to_period[dset_type][\"newest\"]\n",
    "    )\n",
    "    watch_actioned = (\n",
    "        watch[(watch[\"ActionDate\"] >= oldest_dtime) & (watch[\"ActionDate\"] < newest_dtime)]\n",
    "    )\n",
    "    bid_actioned = (\n",
    "        bid[(bid[\"ActionDate\"] >= oldest_dtime) & (bid[\"ActionDate\"] < newest_dtime)]\n",
    "    )\n",
    "    target_actions = (\n",
    "        pd.concat([watch_actioned, bid_actioned], sort=False)\n",
    "    )\n",
    "    return target_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_users_actions(users, auction, watch, bid, rakusatsu,oldest_dtime):\n",
    "\n",
    "    actions = (\n",
    "        pd.concat([watch[watch[\"ActionDate\"] < oldest_dtime],\n",
    "                        bid[bid[\"ActionDate\"] < oldest_dtime]], sort=False)\n",
    "    )\n",
    "    \n",
    "    users_actions = users.merge(actions, on=\"KaiinID\").merge(auction, on=\"AuctionID\")\n",
    "    \n",
    "    return users_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_to_period[\"201909\"] = {\"oldest\": datetime.datetime(2019, 9, 1, 0, 0, 0),\n",
    "              \"newest\": datetime.datetime(2019, 9, 24, 0, 0, 0)}\n",
    "actions = extract_target_actions(watch, bid, dset_to_period, \"201909\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_dtime = dset_to_period[\"201909\"][\"oldest\"]\n",
    "users_actions = extract_users_actions(actions[[\"KaiinID\"]].drop_duplicates(), auction, watch, bid, bid_success, oldest_dtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KaiinID</th>\n",
       "      <th>AuctionID</th>\n",
       "      <th>ActionDate</th>\n",
       "      <th>SakujoFlag</th>\n",
       "      <th>Kingaku</th>\n",
       "      <th>Suuryou</th>\n",
       "      <th>SokketsuFlag</th>\n",
       "      <th>ShouhinShubetsuID</th>\n",
       "      <th>ShouhinID</th>\n",
       "      <th>SaishuppinKaisuu</th>\n",
       "      <th>ConditionID</th>\n",
       "      <th>BrandID</th>\n",
       "      <th>GenreID</th>\n",
       "      <th>GenreGroupID</th>\n",
       "      <th>LineID</th>\n",
       "      <th>ColorID</th>\n",
       "      <th>DanjobetsuID</th>\n",
       "      <th>SankouKakaku</th>\n",
       "      <th>CreateDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56840</td>\n",
       "      <td>681350</td>\n",
       "      <td>2018-09-20 17:34:19</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1879243</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4341</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7800</td>\n",
       "      <td>2018-08-16 10:51:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140863</td>\n",
       "      <td>681350</td>\n",
       "      <td>2018-09-14 23:23:50</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1879243</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4341</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7800</td>\n",
       "      <td>2018-08-16 10:51:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56840</td>\n",
       "      <td>2544841</td>\n",
       "      <td>2018-09-20 17:44:18</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2320686</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4341</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3500</td>\n",
       "      <td>2018-08-25 11:11:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72870</td>\n",
       "      <td>2544841</td>\n",
       "      <td>2018-09-03 07:15:47</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2320686</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4341</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3500</td>\n",
       "      <td>2018-08-25 11:11:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72870</td>\n",
       "      <td>2544841</td>\n",
       "      <td>2018-09-29 21:26:06</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2320686</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4341</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3500</td>\n",
       "      <td>2018-08-25 11:11:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KaiinID  AuctionID          ActionDate  SakujoFlag  Kingaku  Suuryou  \\\n",
       "0    56840     681350 2018-09-20 17:34:19           1      NaN      NaN   \n",
       "1   140863     681350 2018-09-14 23:23:50           1      NaN      NaN   \n",
       "2    56840    2544841 2018-09-20 17:44:18           1      NaN      NaN   \n",
       "3    72870    2544841 2018-09-03 07:15:47           1      NaN      NaN   \n",
       "4    72870    2544841 2018-09-29 21:26:06           1      NaN      NaN   \n",
       "\n",
       "   SokketsuFlag  ShouhinShubetsuID  ShouhinID  SaishuppinKaisuu  ConditionID  \\\n",
       "0           NaN                  1    1879243                 0            6   \n",
       "1           NaN                  1    1879243                 0            6   \n",
       "2           NaN                  1    2320686                 0            7   \n",
       "3           NaN                  1    2320686                 0            7   \n",
       "4           NaN                  1    2320686                 0            7   \n",
       "\n",
       "   BrandID  GenreID  GenreGroupID  LineID  ColorID  DanjobetsuID  \\\n",
       "0     4341       33            33       0        0             2   \n",
       "1     4341       33            33       0        0             2   \n",
       "2     4341       82            19       0        0             2   \n",
       "3     4341       82            19       0        0             2   \n",
       "4     4341       82            19       0        0             2   \n",
       "\n",
       "   SankouKakaku           CreateDate  \n",
       "0          7800  2018-08-16 10:51:32  \n",
       "1          7800  2018-08-16 10:51:32  \n",
       "2          3500  2018-08-25 11:11:21  \n",
       "3          3500  2018-08-25 11:11:21  \n",
       "4          3500  2018-08-25 11:11:21  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KaiinID           NaN\n",
      "ShouhinID    0.865876\n",
      "dtype: float64\n",
      "KaiinID                   NaN\n",
      "ShouhinShubetsuID    0.067124\n",
      "dtype: float64\n",
      "ConditionID    0.131588\n",
      "KaiinID             NaN\n",
      "dtype: float64\n",
      "BrandID    0.279623\n",
      "KaiinID         NaN\n",
      "dtype: float64\n",
      "GenreID    0.226106\n",
      "KaiinID         NaN\n",
      "dtype: float64\n",
      "GenreGroupID    0.151877\n",
      "KaiinID              NaN\n",
      "dtype: float64\n",
      "KaiinID         NaN\n",
      "LineID     0.072249\n",
      "dtype: float64\n",
      "ColorID    0.206427\n",
      "KaiinID         NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for col in [\"ShouhinID\", \"ShouhinShubetsuID\", \"ConditionID\", \"BrandID\", \"GenreID\", \"GenreGroupID\", \"LineID\", \"ColorID\"]:\n",
    "    print((users_actions[[\"KaiinID\", col]].groupby(\"KaiinID\").nunique() / users_actions[[\"KaiinID\", col]].groupby(\"KaiinID\").count()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
